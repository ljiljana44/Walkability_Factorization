{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "notebook\n",
      "Requirement already satisfied: rasterio in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (1.4.3)\n",
      "Requirement already satisfied: affine in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (2.4.0)\n",
      "Requirement already satisfied: attrs in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (25.1.0)\n",
      "Requirement already satisfied: certifi in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (2025.1.31)\n",
      "Requirement already satisfied: click>=4.0 in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (8.1.8)\n",
      "Requirement already satisfied: cligj>=0.5 in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (0.7.2)\n",
      "Requirement already satisfied: numpy>=1.24 in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (2.0.2)\n",
      "Requirement already satisfied: click-plugins in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (1.1.1)\n",
      "Requirement already satisfied: pyparsing in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from rasterio) (3.2.1)\n",
      "Requirement already satisfied: colorama in c:\\projects\\faktorizacije\\.venv\\lib\\site-packages (from click>=4.0->rasterio) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "print('notebook')\n",
    "!pip install rasterio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pandas\n",
    "%pip install surprise\n",
    "%pip install geopy\n",
    "%pip install pyproj\n",
    "%pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Segments transform </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat_1</th>\n",
       "      <th>lon_1</th>\n",
       "      <th>time_1</th>\n",
       "      <th>elev_1</th>\n",
       "      <th>lat_2</th>\n",
       "      <th>lon_2</th>\n",
       "      <th>time_2</th>\n",
       "      <th>elev_2</th>\n",
       "      <th>origname</th>\n",
       "      <th>d_from_start</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>43.516194</td>\n",
       "      <td>16.261334</td>\n",
       "      <td>2018-10-16 14:42:43+00:00</td>\n",
       "      <td>-25.337646</td>\n",
       "      <td>43.516205</td>\n",
       "      <td>16.261316</td>\n",
       "      <td>2018-10-16 14:42:47+00:00</td>\n",
       "      <td>-23.414917</td>\n",
       "      <td>kozjak_svi_tragovi/bili_dolac_planinarenje.gpx</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43.516205</td>\n",
       "      <td>16.261316</td>\n",
       "      <td>2018-10-16 14:42:47+00:00</td>\n",
       "      <td>-23.414917</td>\n",
       "      <td>43.516333</td>\n",
       "      <td>16.261358</td>\n",
       "      <td>2018-10-16 14:43:14+00:00</td>\n",
       "      <td>-24.376343</td>\n",
       "      <td>kozjak_svi_tragovi/bili_dolac_planinarenje.gpx</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>43.516333</td>\n",
       "      <td>16.261358</td>\n",
       "      <td>2018-10-16 14:43:14+00:00</td>\n",
       "      <td>-24.376343</td>\n",
       "      <td>43.516361</td>\n",
       "      <td>16.261331</td>\n",
       "      <td>2018-10-16 14:43:45+00:00</td>\n",
       "      <td>-22.453613</td>\n",
       "      <td>kozjak_svi_tragovi/bili_dolac_planinarenje.gpx</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>43.516361</td>\n",
       "      <td>16.261331</td>\n",
       "      <td>2018-10-16 14:43:45+00:00</td>\n",
       "      <td>-22.453613</td>\n",
       "      <td>43.516337</td>\n",
       "      <td>16.261326</td>\n",
       "      <td>2018-10-16 14:43:47+00:00</td>\n",
       "      <td>-21.973022</td>\n",
       "      <td>kozjak_svi_tragovi/bili_dolac_planinarenje.gpx</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43.516337</td>\n",
       "      <td>16.261326</td>\n",
       "      <td>2018-10-16 14:43:47+00:00</td>\n",
       "      <td>-21.973022</td>\n",
       "      <td>43.516240</td>\n",
       "      <td>16.261314</td>\n",
       "      <td>2018-10-16 14:43:56+00:00</td>\n",
       "      <td>-20.531006</td>\n",
       "      <td>kozjak_svi_tragovi/bili_dolac_planinarenje.gpx</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440285</th>\n",
       "      <td>2440285</td>\n",
       "      <td>45.903425</td>\n",
       "      <td>15.969265</td>\n",
       "      <td>2021-08-12 16:51:01+00:00</td>\n",
       "      <td>932.800000</td>\n",
       "      <td>45.903436</td>\n",
       "      <td>15.969256</td>\n",
       "      <td>2021-08-12 16:51:02+00:00</td>\n",
       "      <td>933.400000</td>\n",
       "      <td>all/Puntijarka_2021_11.gpx</td>\n",
       "      <td>2871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440286</th>\n",
       "      <td>2440286</td>\n",
       "      <td>45.903436</td>\n",
       "      <td>15.969256</td>\n",
       "      <td>2021-08-12 16:51:02+00:00</td>\n",
       "      <td>933.400000</td>\n",
       "      <td>45.903448</td>\n",
       "      <td>15.969252</td>\n",
       "      <td>2021-08-12 16:51:03+00:00</td>\n",
       "      <td>933.800000</td>\n",
       "      <td>all/Puntijarka_2021_11.gpx</td>\n",
       "      <td>2872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440287</th>\n",
       "      <td>2440287</td>\n",
       "      <td>45.903448</td>\n",
       "      <td>15.969252</td>\n",
       "      <td>2021-08-12 16:51:03+00:00</td>\n",
       "      <td>933.800000</td>\n",
       "      <td>45.903467</td>\n",
       "      <td>15.969259</td>\n",
       "      <td>2021-08-12 16:51:04+00:00</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>all/Puntijarka_2021_11.gpx</td>\n",
       "      <td>2873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440288</th>\n",
       "      <td>2440288</td>\n",
       "      <td>45.903467</td>\n",
       "      <td>15.969259</td>\n",
       "      <td>2021-08-12 16:51:04+00:00</td>\n",
       "      <td>934.000000</td>\n",
       "      <td>45.903485</td>\n",
       "      <td>15.969257</td>\n",
       "      <td>2021-08-12 16:51:05+00:00</td>\n",
       "      <td>934.400000</td>\n",
       "      <td>all/Puntijarka_2021_11.gpx</td>\n",
       "      <td>2874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2440289</th>\n",
       "      <td>2440289</td>\n",
       "      <td>45.903485</td>\n",
       "      <td>15.969257</td>\n",
       "      <td>2021-08-12 16:51:05+00:00</td>\n",
       "      <td>934.400000</td>\n",
       "      <td>45.903494</td>\n",
       "      <td>15.969253</td>\n",
       "      <td>2021-08-12 16:51:06+00:00</td>\n",
       "      <td>935.000000</td>\n",
       "      <td>all/Puntijarka_2021_11.gpx</td>\n",
       "      <td>2875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2440290 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0      lat_1      lon_1                     time_1  \\\n",
       "0                 0  43.516194  16.261334  2018-10-16 14:42:43+00:00   \n",
       "1                 1  43.516205  16.261316  2018-10-16 14:42:47+00:00   \n",
       "2                 2  43.516333  16.261358  2018-10-16 14:43:14+00:00   \n",
       "3                 3  43.516361  16.261331  2018-10-16 14:43:45+00:00   \n",
       "4                 4  43.516337  16.261326  2018-10-16 14:43:47+00:00   \n",
       "...             ...        ...        ...                        ...   \n",
       "2440285     2440285  45.903425  15.969265  2021-08-12 16:51:01+00:00   \n",
       "2440286     2440286  45.903436  15.969256  2021-08-12 16:51:02+00:00   \n",
       "2440287     2440287  45.903448  15.969252  2021-08-12 16:51:03+00:00   \n",
       "2440288     2440288  45.903467  15.969259  2021-08-12 16:51:04+00:00   \n",
       "2440289     2440289  45.903485  15.969257  2021-08-12 16:51:05+00:00   \n",
       "\n",
       "             elev_1      lat_2      lon_2                     time_2  \\\n",
       "0        -25.337646  43.516205  16.261316  2018-10-16 14:42:47+00:00   \n",
       "1        -23.414917  43.516333  16.261358  2018-10-16 14:43:14+00:00   \n",
       "2        -24.376343  43.516361  16.261331  2018-10-16 14:43:45+00:00   \n",
       "3        -22.453613  43.516337  16.261326  2018-10-16 14:43:47+00:00   \n",
       "4        -21.973022  43.516240  16.261314  2018-10-16 14:43:56+00:00   \n",
       "...             ...        ...        ...                        ...   \n",
       "2440285  932.800000  45.903436  15.969256  2021-08-12 16:51:02+00:00   \n",
       "2440286  933.400000  45.903448  15.969252  2021-08-12 16:51:03+00:00   \n",
       "2440287  933.800000  45.903467  15.969259  2021-08-12 16:51:04+00:00   \n",
       "2440288  934.000000  45.903485  15.969257  2021-08-12 16:51:05+00:00   \n",
       "2440289  934.400000  45.903494  15.969253  2021-08-12 16:51:06+00:00   \n",
       "\n",
       "             elev_2                                        origname  \\\n",
       "0        -23.414917  kozjak_svi_tragovi/bili_dolac_planinarenje.gpx   \n",
       "1        -24.376343  kozjak_svi_tragovi/bili_dolac_planinarenje.gpx   \n",
       "2        -22.453613  kozjak_svi_tragovi/bili_dolac_planinarenje.gpx   \n",
       "3        -21.973022  kozjak_svi_tragovi/bili_dolac_planinarenje.gpx   \n",
       "4        -20.531006  kozjak_svi_tragovi/bili_dolac_planinarenje.gpx   \n",
       "...             ...                                             ...   \n",
       "2440285  933.400000                      all/Puntijarka_2021_11.gpx   \n",
       "2440286  933.800000                      all/Puntijarka_2021_11.gpx   \n",
       "2440287  934.000000                      all/Puntijarka_2021_11.gpx   \n",
       "2440288  934.400000                      all/Puntijarka_2021_11.gpx   \n",
       "2440289  935.000000                      all/Puntijarka_2021_11.gpx   \n",
       "\n",
       "         d_from_start  \n",
       "0                   0  \n",
       "1                   1  \n",
       "2                   2  \n",
       "3                   3  \n",
       "4                   4  \n",
       "...               ...  \n",
       "2440285          2871  \n",
       "2440286          2872  \n",
       "2440287          2873  \n",
       "2440288          2874  \n",
       "2440289          2875  \n",
       "\n",
       "[2440290 rows x 11 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "folder=\"./\"\n",
    "file_path = folder+\"seg_all.csv\"\n",
    "df = pd.read_csv(file_path, delimiter=',')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'time_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Projects\\Faktorizacije\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df\u001b[38;5;241m=\u001b[39mdf[\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtime_1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m==\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m]\n\u001b[0;32m      2\u001b[0m df\n",
      "File \u001b[1;32mc:\\Projects\\Faktorizacije\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[1;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[0;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[1;32mc:\\Projects\\Faktorizacije\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'time_1'"
     ]
    }
   ],
   "source": [
    "df=df[df['time_1'].isna()==False]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from geopy.distance import geodesic\n",
    "#from pandarallel import pandarallel\n",
    "import pandas as pd\n",
    "\n",
    "# Inicijalizacija pandarallel (koristi sve dostupne jezgre)\n",
    "#pandarallel.initialize(progress_bar=True)\n",
    "\n",
    "# Funkcija za računanje vrednosti po redu\n",
    "def process_row(row):\n",
    "    try:\n",
    "        point1 = (row['lat_1'], row['lon_1'])\n",
    "        point2 = (row['lat_2'], row['lon_2'])\n",
    "\n",
    "        # Parsiranje vremena\n",
    "        if 'Z' in row['time_1']:\n",
    "            time1 = datetime.fromisoformat(row['time_1'].replace(\"Z\", \"+00:00\"))\n",
    "            time2 = datetime.fromisoformat(row['time_2'].replace(\"Z\", \"+00:00\"))\n",
    "        else:\n",
    "            time1 = datetime.fromisoformat(row['time_1'])\n",
    "            time2 = datetime.fromisoformat(row['time_2'])\n",
    "\n",
    "        # Razlika u nadmorskoj visini\n",
    "        elev_diff = row['elev_2'] - row['elev_1']\n",
    "\n",
    "        # Izračunaj rastojanje (u metrima) i vreme (u sekundama)\n",
    "        distance = geodesic(point1, point2).meters\n",
    "        time_diff = (time2 - time1).total_seconds()\n",
    "\n",
    "        # Izračunaj brzinu (m/s) i nagib (%)\n",
    "        speed = distance / time_diff if time_diff > 0 else 0\n",
    "        slope = (elev_diff / distance) * 100 if distance > 0 else 0\n",
    "\n",
    "        return pd.Series([distance, time_diff, speed, slope])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e, row['time_1'])\n",
    "        return pd.Series([None, None, None, None])\n",
    "\n",
    "# Paralelna obrada podataka\n",
    "df[['distance_m', 'time_s', 'speed_m_s', 'slope_percent']] = df.apply(process_row, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Helper function to calculate speed (m/s)\n",
    "def calculate_speed(dist_meters, time_seconds):\n",
    "    return dist_meters / time_seconds if time_seconds > 0 else 0\n",
    "\n",
    "# Helper function to calculate slope\n",
    "def calculate_slope(elev_diff, dist_meters):\n",
    "    return (elev_diff / dist_meters) * 100 if dist_meters > 0 else 0\n",
    "\n",
    "# Add calculated columns\n",
    "distances = []\n",
    "times = []\n",
    "speeds = []\n",
    "slopes = []\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    # Get coordinates and timestamps\n",
    "    point1 = (row['lat_1'], row['lon_1'])\n",
    "    point2 = (row['lat_2'], row['lon_2'])\n",
    "    try:\n",
    "      if 'Z' in row['time_1']:\n",
    "\n",
    "        time1 = datetime.fromisoformat(row['time_1'].replace(\"Z\", \"+00:00\"))\n",
    "        time2 = datetime.fromisoformat(row['time_2'].replace(\"Z\", \"+00:00\"))\n",
    "      else :\n",
    "        time1 = datetime.fromisoformat(row['time_1'])\n",
    "        time2 = datetime.fromisoformat(row['time_2'])\n",
    "\n",
    "    except Exception as e:\n",
    "\n",
    "      print(e,row['time_1'],index)\n",
    "      time1=datetime.fromisoformat(\"2012-10-12\")\n",
    "      time2=datetime.fromisoformat(\"2012-10-12\")\n",
    "\n",
    "\n",
    "    elev_diff = row['elev_2'] - row['elev_1']\n",
    "\n",
    "    # Calculate distance (meters) and time (seconds)\n",
    "    distance = geodesic(point1, point2).meters\n",
    "    time_diff = (time2 - time1).total_seconds()\n",
    "\n",
    "    # Calculate speed (m/s) and slope (%)\n",
    "    speed = calculate_speed(distance, time_diff)\n",
    "    #slope = calculate_slope(elev_diff, distance)\n",
    "\n",
    "    # Append results\n",
    "    distances.append(distance)\n",
    "    times.append(time_diff)\n",
    "    speeds.append(speed)\n",
    "    #slopes.append(slope)\n",
    "\n",
    "# Add results to the DataFrame\n",
    "df['distance_m'] = distances\n",
    "df['time_s'] = times\n",
    "df['speed_m_s'] = speeds\n",
    "#df['slope_percent'] = slopes\n",
    "\n",
    "# Save the results to a CSV file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>867241.000000</td>\n",
       "      <td>867241.000000</td>\n",
       "      <td>867241.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>806.180377</td>\n",
       "      <td>177969.174308</td>\n",
       "      <td>4.814165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>505.390282</td>\n",
       "      <td>95394.019497</td>\n",
       "      <td>38.663469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>335.000000</td>\n",
       "      <td>90458.000000</td>\n",
       "      <td>0.824075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>783.000000</td>\n",
       "      <td>187203.000000</td>\n",
       "      <td>1.275855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1288.000000</td>\n",
       "      <td>267324.000000</td>\n",
       "      <td>4.557777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1619.000000</td>\n",
       "      <td>328792.000000</td>\n",
       "      <td>14747.044681</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user           item         rating\n",
       "count  867241.000000  867241.000000  867241.000000\n",
       "mean      806.180377  177969.174308       4.814165\n",
       "std       505.390282   95394.019497      38.663469\n",
       "min         0.000000       0.000000       0.003469\n",
       "25%       335.000000   90458.000000       0.824075\n",
       "50%       783.000000  187203.000000       1.275855\n",
       "75%      1288.000000  267324.000000       4.557777\n",
       "max      1619.000000  328792.000000   14747.044681"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['time_s']>0]\n",
    "df=df[df['time_s']<60]\n",
    "df=df[df['distance_m']<50]\n",
    "df=df[df['distance_m']>0]\n",
    "\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#print(df['time_s'].value_counts())\n",
    "plt.scatter(df['time_s'].value_counts().index,df['time_s'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#print(df['time_s'].value_counts())\n",
    "\n",
    "plt.scatter(df['distance_m'].value_counts().index,df['distance_m'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['speed_m_s']<50]\n",
    "plt.scatter(df['d_from_start'],df['speed_m_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "#print(df['time_s'].value_counts())\n",
    "plt.scatter(df['speed_m_s'].value_counts().index,df['speed_m_s'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['speed_m_s'].describe()\n",
    "\n",
    "#plt.scatter(df['time_s'],df['speed_m_s'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[df['distance_m']<50]\n",
    "df['distance_m'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=df.groupby('origname')[['speed_m_s']].agg(['mean','median','std']).reset_index()\n",
    "\n",
    "#g1[g1['mean']>15]\n",
    "nevalja=[]\n",
    "for  n in g1[g1['speed_m_s']['median']>20]['origname'] :\n",
    "    print(n)\n",
    "    nevalja.append(n)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in nevalja:\n",
    "  df=df[df['origname']!=s]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import Transformer\n",
    "\n",
    "trans = Transformer.from_crs(\n",
    "    \"epsg:4326\",\n",
    "  #  \"+proj=utm +zone=10 +ellps=WGS84\",\n",
    "  \"epsg:3765\",\n",
    "    always_xy=True,\n",
    ")\n",
    "#32610\n",
    "xx, yy = trans.transform(df[\"lon_1\"].values, df[\"lat_1\"].values)\n",
    "xx2, yy2 = trans.transform(df[\"lon_2\"].values, df[\"lat_2\"].values)\n",
    "\n",
    "df[\"N1\"] = xx\n",
    "df[\"E1\"] = yy\n",
    "df[\"N2\"] = xx2\n",
    "df[\"E2\"] = yy2\n",
    "import math\n",
    "frameForGroup=df.copy()\n",
    "num_round=-1\n",
    "def distance_utm(row):\n",
    "  n1=row.lat_1\n",
    "  e1=row.lon_1\n",
    "  n2=row.lat_2\n",
    "  e2=row.lon_2\n",
    "  x=n2-n1\n",
    "  y=e2-e1\n",
    "  c=math.sqrt(x*x+y*y)\n",
    "  return c\n",
    "def calc_slope(e_d,d_D):\n",
    "  if e_d==0:\n",
    "    return 0\n",
    "  if d_D==0:\n",
    "    return 0\n",
    "  return e_d/(d_D*1000)\n",
    "frameForGroup['lat_1']=round(frameForGroup['N1'], num_round)\n",
    "frameForGroup['lon_1']=round(frameForGroup['E1'], num_round)\n",
    "frameForGroup['lat_2']=round(frameForGroup['N2'], num_round)\n",
    "frameForGroup['lon_2']=round(frameForGroup['E2'], num_round)\n",
    "frameForGroup['dist_utm']=frameForGroup.apply(distance_utm,axis=1)\n",
    "#frame['angle_utm']=frame.apply (lambda row: calc_slope(row['elev_d'],row['dist_utm']) , axis=1) # df['elev_d']/(df['dist_2d_wgs']*1000)\n",
    "\n",
    "frameForGroup['speed_utm']=frameForGroup['dist_utm']/frameForGroup['time_s']\n",
    "#frameForGroup['angle_utm']=frameForGroup['elev_d']/frameForGroup['dist_utm']\n",
    "#frameForGroup['angle_utm']=frameForGroup.apply (lambda row: calc_slope(row['elev_d'],row['dist_utm']) , axis=1) # df['elev_d']/(df['dist_2d_wgs']*1000)\n",
    "\n",
    "#frameForGroup=frameForGroup[frameForGroup['time_d_s']<50]\n",
    "frameForGroup=frameForGroup[frameForGroup['speed_utm']<10]\n",
    "#frameForGroup['latlon']=frameForGroup.apply (lambda row: str(row['lat_1']).strip()+'_'+str(row['lon_1']).strip()+'_'+str(row['lat_2']).strip()+'_'+str(row['lon_2']).strip() , axis=1)\n",
    "\n",
    "\n",
    "frameForGroup['latlon']=frameForGroup.apply (lambda row: str(row['lat_1']).strip()+'_'+str(row['lon_1']).strip()  , axis=1)\n",
    "\n",
    "#frameForGroup['latlon']=frameForGroup.apply (lambda row: str(row['lat_1']).strip()+'_'+str(row['lon_1']).strip()+'_'+str(row['lat_2']).strip()+'_'+str(row['lon_2']).strip() , axis=1)\n",
    "frameForGroup[\"origname_encoded\"] = frameForGroup[\"origname\"].astype(\"category\").cat.codes\n",
    "\n",
    "\n",
    "# Normalize frequencies to avoid dominance of this feature in PCA\n",
    "frameForGroup['latlon_encoded'] = frameForGroup[\"latlon\"].astype(\"category\").cat.codes\n",
    "\n",
    "frameForGroup.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frameForGroup['latlon'].value_counts()[frameForGroup['latlon'].value_counts()>5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_frame=frameForGroup[['lat_1', 'lon_1',   'lat_2', 'lon_2','distance_m', 'time_s', 'speed_m_s',\n",
    "       'slope_percent',    'origname_encoded', 'N1', 'E1', 'N2',\n",
    "       'E2', 'dist_utm','latlon_encoded']].groupby(['latlon_encoded','origname_encoded']).agg('median')\n",
    "dd=grouped_frame[[ 'distance_m', 'time_s', 'speed_m_s', 'slope_percent' ]].apply(lambda x: x)\n",
    "\n",
    "dd=dd.reset_index()\n",
    "\n",
    "col_sel=['elev_1','distance_m', 'time_s', 'speed_m_s',\n",
    "       'slope_percent', 'curvature_rad']\n",
    "\n",
    "col_Sel2=[]\n",
    "numerical_data=dd[['latlon_encoded','origname_encoded','speed_m_s']]\n",
    "numerical_data.to_csv('numerical_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>frameforgroup</h1>\n",
    ">>frameforgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "frameForGroup=pd.read_csv('frameForGroup-2.csv')\n",
    "frameForGroup[['latlon','latlon_encoded']]\n",
    "grouped_frame=frameForGroup[['lat_1', 'lon_1',   'lat_2', 'lon_2','distance_m', 'time_s', 'speed_m_s',\n",
    "        'origname_encoded', 'N1', 'E1', 'N2',\n",
    "       'E2', 'latlon_encoded']].groupby(['latlon_encoded','origname_encoded']).agg('median')\n",
    "dd=grouped_frame[[ 'distance_m', 'time_s', 'speed_m_s' ]].apply(lambda x: x)\n",
    "\n",
    "dd=dd.reset_index()\n",
    "numerical_data=dd[['latlon_encoded','origname_encoded','speed_m_s']]\n",
    "#numerical_data=frameForGroup[['origname_encoded','latlon_encoded','speed_m_s']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerical_data['latlon_encoded'][numerical_data['latlon_encoded']==.value_counts()==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>lat_1</th>\n",
       "      <th>lon_1</th>\n",
       "      <th>time_1</th>\n",
       "      <th>elev_1</th>\n",
       "      <th>lat_2</th>\n",
       "      <th>lon_2</th>\n",
       "      <th>time_2</th>\n",
       "      <th>elev_2</th>\n",
       "      <th>...</th>\n",
       "      <th>speed_m_s</th>\n",
       "      <th>N1</th>\n",
       "      <th>E1</th>\n",
       "      <th>N2</th>\n",
       "      <th>E2</th>\n",
       "      <th>N11</th>\n",
       "      <th>E11</th>\n",
       "      <th>latlon</th>\n",
       "      <th>origname_encoded</th>\n",
       "      <th>latlon_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>45.870106</td>\n",
       "      <td>15.978680</td>\n",
       "      <td>2017-10-04 03:29:55+00:00</td>\n",
       "      <td>411.0</td>\n",
       "      <td>45.870192</td>\n",
       "      <td>15.978656</td>\n",
       "      <td>2017-10-04 03:29:59+00:00</td>\n",
       "      <td>411.2</td>\n",
       "      <td>...</td>\n",
       "      <td>2.434685</td>\n",
       "      <td>459526.504015</td>\n",
       "      <td>5.081272e+06</td>\n",
       "      <td>459524.703163</td>\n",
       "      <td>5.081282e+06</td>\n",
       "      <td>459500.0</td>\n",
       "      <td>5081300.0</td>\n",
       "      <td>459500.0_5081300.0</td>\n",
       "      <td>708</td>\n",
       "      <td>15209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45.870192</td>\n",
       "      <td>15.978656</td>\n",
       "      <td>2017-10-04 03:29:59+00:00</td>\n",
       "      <td>411.2</td>\n",
       "      <td>45.870264</td>\n",
       "      <td>15.978623</td>\n",
       "      <td>2017-10-04 03:30:01+00:00</td>\n",
       "      <td>411.4</td>\n",
       "      <td>...</td>\n",
       "      <td>4.201445</td>\n",
       "      <td>459524.703163</td>\n",
       "      <td>5.081282e+06</td>\n",
       "      <td>459522.193428</td>\n",
       "      <td>5.081290e+06</td>\n",
       "      <td>459500.0</td>\n",
       "      <td>5081300.0</td>\n",
       "      <td>459500.0_5081300.0</td>\n",
       "      <td>708</td>\n",
       "      <td>15209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>45.870264</td>\n",
       "      <td>15.978623</td>\n",
       "      <td>2017-10-04 03:30:01+00:00</td>\n",
       "      <td>411.4</td>\n",
       "      <td>45.870410</td>\n",
       "      <td>15.978569</td>\n",
       "      <td>2017-10-04 03:30:08+00:00</td>\n",
       "      <td>412.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.394374</td>\n",
       "      <td>459522.193428</td>\n",
       "      <td>5.081290e+06</td>\n",
       "      <td>459518.107063</td>\n",
       "      <td>5.081306e+06</td>\n",
       "      <td>459500.0</td>\n",
       "      <td>5081300.0</td>\n",
       "      <td>459500.0_5081300.0</td>\n",
       "      <td>708</td>\n",
       "      <td>15209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>45.870410</td>\n",
       "      <td>15.978569</td>\n",
       "      <td>2017-10-04 03:30:08+00:00</td>\n",
       "      <td>412.0</td>\n",
       "      <td>45.870463</td>\n",
       "      <td>15.978495</td>\n",
       "      <td>2017-10-04 03:30:34+00:00</td>\n",
       "      <td>413.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.316497</td>\n",
       "      <td>459518.107063</td>\n",
       "      <td>5.081306e+06</td>\n",
       "      <td>459512.400476</td>\n",
       "      <td>5.081312e+06</td>\n",
       "      <td>459500.0</td>\n",
       "      <td>5081300.0</td>\n",
       "      <td>459500.0_5081300.0</td>\n",
       "      <td>708</td>\n",
       "      <td>15209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>45.870463</td>\n",
       "      <td>15.978495</td>\n",
       "      <td>2017-10-04 03:30:34+00:00</td>\n",
       "      <td>413.2</td>\n",
       "      <td>45.870427</td>\n",
       "      <td>15.978527</td>\n",
       "      <td>2017-10-04 03:30:42+00:00</td>\n",
       "      <td>415.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.588750</td>\n",
       "      <td>459512.400476</td>\n",
       "      <td>5.081312e+06</td>\n",
       "      <td>459514.858690</td>\n",
       "      <td>5.081308e+06</td>\n",
       "      <td>459500.0</td>\n",
       "      <td>5081300.0</td>\n",
       "      <td>459500.0_5081300.0</td>\n",
       "      <td>708</td>\n",
       "      <td>15209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795658</th>\n",
       "      <td>2055443</td>\n",
       "      <td>2055443</td>\n",
       "      <td>45.875111</td>\n",
       "      <td>16.012690</td>\n",
       "      <td>2017-12-30 13:27:18+00:00</td>\n",
       "      <td>234.6</td>\n",
       "      <td>45.875185</td>\n",
       "      <td>16.012767</td>\n",
       "      <td>2017-12-30 13:27:24+00:00</td>\n",
       "      <td>233.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.694667</td>\n",
       "      <td>462170.317741</td>\n",
       "      <td>5.081812e+06</td>\n",
       "      <td>462176.345420</td>\n",
       "      <td>5.081820e+06</td>\n",
       "      <td>462200.0</td>\n",
       "      <td>5081800.0</td>\n",
       "      <td>462200.0_5081800.0</td>\n",
       "      <td>53</td>\n",
       "      <td>15716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795659</th>\n",
       "      <td>2055444</td>\n",
       "      <td>2055444</td>\n",
       "      <td>45.875185</td>\n",
       "      <td>16.012767</td>\n",
       "      <td>2017-12-30 13:27:24+00:00</td>\n",
       "      <td>233.9</td>\n",
       "      <td>45.875238</td>\n",
       "      <td>16.012865</td>\n",
       "      <td>2017-12-30 13:27:32+00:00</td>\n",
       "      <td>233.3</td>\n",
       "      <td>...</td>\n",
       "      <td>1.202803</td>\n",
       "      <td>462176.345420</td>\n",
       "      <td>5.081820e+06</td>\n",
       "      <td>462183.989055</td>\n",
       "      <td>5.081826e+06</td>\n",
       "      <td>462200.0</td>\n",
       "      <td>5081800.0</td>\n",
       "      <td>462200.0_5081800.0</td>\n",
       "      <td>53</td>\n",
       "      <td>15716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795660</th>\n",
       "      <td>2055445</td>\n",
       "      <td>2055445</td>\n",
       "      <td>45.875238</td>\n",
       "      <td>16.012865</td>\n",
       "      <td>2017-12-30 13:27:32+00:00</td>\n",
       "      <td>233.3</td>\n",
       "      <td>45.875296</td>\n",
       "      <td>16.012935</td>\n",
       "      <td>2017-12-30 13:27:36+00:00</td>\n",
       "      <td>232.8</td>\n",
       "      <td>...</td>\n",
       "      <td>2.107932</td>\n",
       "      <td>462183.989055</td>\n",
       "      <td>5.081826e+06</td>\n",
       "      <td>462189.462446</td>\n",
       "      <td>5.081832e+06</td>\n",
       "      <td>462200.0</td>\n",
       "      <td>5081800.0</td>\n",
       "      <td>462200.0_5081800.0</td>\n",
       "      <td>53</td>\n",
       "      <td>15716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795661</th>\n",
       "      <td>2055446</td>\n",
       "      <td>2055446</td>\n",
       "      <td>45.875296</td>\n",
       "      <td>16.012935</td>\n",
       "      <td>2017-12-30 13:27:36+00:00</td>\n",
       "      <td>232.8</td>\n",
       "      <td>45.875298</td>\n",
       "      <td>16.013084</td>\n",
       "      <td>2017-12-30 13:27:42+00:00</td>\n",
       "      <td>232.2</td>\n",
       "      <td>...</td>\n",
       "      <td>1.928345</td>\n",
       "      <td>462189.462446</td>\n",
       "      <td>5.081832e+06</td>\n",
       "      <td>462201.030567</td>\n",
       "      <td>5.081832e+06</td>\n",
       "      <td>462200.0</td>\n",
       "      <td>5081800.0</td>\n",
       "      <td>462200.0_5081800.0</td>\n",
       "      <td>53</td>\n",
       "      <td>15716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795662</th>\n",
       "      <td>2055447</td>\n",
       "      <td>2055447</td>\n",
       "      <td>45.875298</td>\n",
       "      <td>16.013084</td>\n",
       "      <td>2017-12-30 13:27:42+00:00</td>\n",
       "      <td>232.2</td>\n",
       "      <td>45.875292</td>\n",
       "      <td>16.013145</td>\n",
       "      <td>2017-12-30 13:27:45+00:00</td>\n",
       "      <td>231.9</td>\n",
       "      <td>...</td>\n",
       "      <td>1.594197</td>\n",
       "      <td>462201.030567</td>\n",
       "      <td>5.081832e+06</td>\n",
       "      <td>462205.761886</td>\n",
       "      <td>5.081832e+06</td>\n",
       "      <td>462200.0</td>\n",
       "      <td>5081800.0</td>\n",
       "      <td>462200.0_5081800.0</td>\n",
       "      <td>53</td>\n",
       "      <td>15716</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1795663 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Unnamed: 0.1  Unnamed: 0      lat_1      lon_1  \\\n",
       "0                   0           0  45.870106  15.978680   \n",
       "1                   1           1  45.870192  15.978656   \n",
       "2                   2           2  45.870264  15.978623   \n",
       "3                   3           3  45.870410  15.978569   \n",
       "4                   4           4  45.870463  15.978495   \n",
       "...               ...         ...        ...        ...   \n",
       "1795658       2055443     2055443  45.875111  16.012690   \n",
       "1795659       2055444     2055444  45.875185  16.012767   \n",
       "1795660       2055445     2055445  45.875238  16.012865   \n",
       "1795661       2055446     2055446  45.875296  16.012935   \n",
       "1795662       2055447     2055447  45.875298  16.013084   \n",
       "\n",
       "                            time_1  elev_1      lat_2      lon_2  \\\n",
       "0        2017-10-04 03:29:55+00:00   411.0  45.870192  15.978656   \n",
       "1        2017-10-04 03:29:59+00:00   411.2  45.870264  15.978623   \n",
       "2        2017-10-04 03:30:01+00:00   411.4  45.870410  15.978569   \n",
       "3        2017-10-04 03:30:08+00:00   412.0  45.870463  15.978495   \n",
       "4        2017-10-04 03:30:34+00:00   413.2  45.870427  15.978527   \n",
       "...                            ...     ...        ...        ...   \n",
       "1795658  2017-12-30 13:27:18+00:00   234.6  45.875185  16.012767   \n",
       "1795659  2017-12-30 13:27:24+00:00   233.9  45.875238  16.012865   \n",
       "1795660  2017-12-30 13:27:32+00:00   233.3  45.875296  16.012935   \n",
       "1795661  2017-12-30 13:27:36+00:00   232.8  45.875298  16.013084   \n",
       "1795662  2017-12-30 13:27:42+00:00   232.2  45.875292  16.013145   \n",
       "\n",
       "                            time_2  elev_2  ... speed_m_s             N1  \\\n",
       "0        2017-10-04 03:29:59+00:00   411.2  ...  2.434685  459526.504015   \n",
       "1        2017-10-04 03:30:01+00:00   411.4  ...  4.201445  459524.703163   \n",
       "2        2017-10-04 03:30:08+00:00   412.0  ...  2.394374  459522.193428   \n",
       "3        2017-10-04 03:30:34+00:00   413.2  ...  0.316497  459518.107063   \n",
       "4        2017-10-04 03:30:42+00:00   415.2  ...  0.588750  459512.400476   \n",
       "...                            ...     ...  ...       ...            ...   \n",
       "1795658  2017-12-30 13:27:24+00:00   233.9  ...  1.694667  462170.317741   \n",
       "1795659  2017-12-30 13:27:32+00:00   233.3  ...  1.202803  462176.345420   \n",
       "1795660  2017-12-30 13:27:36+00:00   232.8  ...  2.107932  462183.989055   \n",
       "1795661  2017-12-30 13:27:42+00:00   232.2  ...  1.928345  462189.462446   \n",
       "1795662  2017-12-30 13:27:45+00:00   231.9  ...  1.594197  462201.030567   \n",
       "\n",
       "                   E1             N2            E2       N11        E11  \\\n",
       "0        5.081272e+06  459524.703163  5.081282e+06  459500.0  5081300.0   \n",
       "1        5.081282e+06  459522.193428  5.081290e+06  459500.0  5081300.0   \n",
       "2        5.081290e+06  459518.107063  5.081306e+06  459500.0  5081300.0   \n",
       "3        5.081306e+06  459512.400476  5.081312e+06  459500.0  5081300.0   \n",
       "4        5.081312e+06  459514.858690  5.081308e+06  459500.0  5081300.0   \n",
       "...               ...            ...           ...       ...        ...   \n",
       "1795658  5.081812e+06  462176.345420  5.081820e+06  462200.0  5081800.0   \n",
       "1795659  5.081820e+06  462183.989055  5.081826e+06  462200.0  5081800.0   \n",
       "1795660  5.081826e+06  462189.462446  5.081832e+06  462200.0  5081800.0   \n",
       "1795661  5.081832e+06  462201.030567  5.081832e+06  462200.0  5081800.0   \n",
       "1795662  5.081832e+06  462205.761886  5.081832e+06  462200.0  5081800.0   \n",
       "\n",
       "                     latlon  origname_encoded  latlon_encoded  \n",
       "0        459500.0_5081300.0               708           15209  \n",
       "1        459500.0_5081300.0               708           15209  \n",
       "2        459500.0_5081300.0               708           15209  \n",
       "3        459500.0_5081300.0               708           15209  \n",
       "4        459500.0_5081300.0               708           15209  \n",
       "...                     ...               ...             ...  \n",
       "1795658  462200.0_5081800.0                53           15716  \n",
       "1795659  462200.0_5081800.0                53           15716  \n",
       "1795660  462200.0_5081800.0                53           15716  \n",
       "1795661  462200.0_5081800.0                53           15716  \n",
       "1795662  462200.0_5081800.0                53           15716  \n",
       "\n",
       "[1795663 rows x 24 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "frameForGroup[['latlon','latlon_encoded']]\n",
    "frameForGroup['latlon_encoded'].unique()\n",
    "latlon_dict = frameForGroup.set_index('latlon_encoded')['latlon'].to_dict()\n",
    "lat_dict=frameForGroup.set_index('latlon_encoded')['lat_1'].to_dict()\n",
    "lon_dict=frameForGroup.set_index('latlon_encoded')['lon_1'].to_dict()\n",
    "N1_dict=frameForGroup.set_index('latlon_encoded')['N1'].to_dict()\n",
    "E1_dict=frameForGroup.set_index('latlon_encoded')['E1'].to_dict()\n",
    "frameForGroup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NMF</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>latlon_encoded</th>\n",
       "      <th>origname_encoded</th>\n",
       "      <th>speed_m_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127478.000000</td>\n",
       "      <td>127478.000000</td>\n",
       "      <td>127478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>13419.156843</td>\n",
       "      <td>798.264752</td>\n",
       "      <td>5.730168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>7045.483651</td>\n",
       "      <td>512.689488</td>\n",
       "      <td>5.837716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6539.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>1.017070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>14778.000000</td>\n",
       "      <td>746.000000</td>\n",
       "      <td>2.445403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>20036.000000</td>\n",
       "      <td>1320.000000</td>\n",
       "      <td>10.223014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>24348.000000</td>\n",
       "      <td>1608.000000</td>\n",
       "      <td>19.999193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       latlon_encoded  origname_encoded      speed_m_s\n",
       "count   127478.000000     127478.000000  127478.000000\n",
       "mean     13419.156843        798.264752       5.730168\n",
       "std       7045.483651        512.689488       5.837716\n",
       "min          0.000000          0.000000       0.013087\n",
       "25%       6539.000000        329.000000       1.017070\n",
       "50%      14778.000000        746.000000       2.445403\n",
       "75%      20036.000000       1320.000000      10.223014\n",
       "max      24348.000000       1608.000000      19.999193"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF,non_negative_factorization\n",
    "from sklearn.metrics import mean_squared_error\n",
    "ratings_dict = {\n",
    "    \"user\": numerical_data['origname_encoded'].values,\n",
    "    \"item\": numerical_data['latlon_encoded'].values,\n",
    "    \"rating\": numerical_data['speed_m_s'].values\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "user_item_matrix = df.pivot(index=\"user\", columns=\"item\", values=\"rating\").fillna(0)\n",
    "#print(user_item_matrix)\n",
    "\n",
    "nmf = NMF(n_components=1, init='nndsvd', random_state=42)\n",
    "\n",
    "# Factorize user-item matrix into W (Users) and H (Items)\n",
    "W_nmf = nmf.fit_transform(user_item_matrix)  # User features\n",
    "H_nmf = nmf.components_  # Item features\n",
    "\n",
    "#print(\"User Features Matrix (W):\\n\", W)\n",
    "#print(\"Item Features Matrix (H):\\n\", H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user</th>\n",
       "      <th>item</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>127478.000000</td>\n",
       "      <td>127478.000000</td>\n",
       "      <td>127478.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>798.264752</td>\n",
       "      <td>13419.156843</td>\n",
       "      <td>5.730168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>512.689488</td>\n",
       "      <td>7045.483651</td>\n",
       "      <td>5.837716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>329.000000</td>\n",
       "      <td>6539.000000</td>\n",
       "      <td>1.017070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>746.000000</td>\n",
       "      <td>14778.000000</td>\n",
       "      <td>2.445403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1320.000000</td>\n",
       "      <td>20036.000000</td>\n",
       "      <td>10.223014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1608.000000</td>\n",
       "      <td>24348.000000</td>\n",
       "      <td>19.999193</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                user           item         rating\n",
       "count  127478.000000  127478.000000  127478.000000\n",
       "mean      798.264752   13419.156843       5.730168\n",
       "std       512.689488    7045.483651       5.837716\n",
       "min         0.000000       0.000000       0.013087\n",
       "25%       329.000000    6539.000000       1.017070\n",
       "50%       746.000000   14778.000000       2.445403\n",
       "75%      1320.000000   20036.000000      10.223014\n",
       "max      1608.000000   24348.000000      19.999193"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0032538540384655585"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix.shape\n",
    "df.shape[0]/user_item_matrix.size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>evaluate nmf</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4148\n"
     ]
    }
   ],
   "source": [
    "reconstructed_ratings = np.dot(W_nmf, H_nmf)\n",
    "reconstructed_ratings\n",
    "user_item_matrix[user_item_matrix>0]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(user_item_matrix, reconstructed_ratings))\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>non_negative_factorization</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_non, H_non, n_iter = non_negative_factorization(user_item_matrix, n_components=1, init='random', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4148\n"
     ]
    }
   ],
   "source": [
    "reconstructed_ratings = np.dot(W_non, H_non)\n",
    "reconstructed_ratings\n",
    "user_item_matrix[user_item_matrix>0]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(user_item_matrix, reconstructed_ratings))\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SVD s</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted rating for user 0 and item 10: 0.00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse.linalg import svds\n",
    "\n",
    "# ✅ Example Dataset\n",
    " \n",
    "\n",
    "# Create a sample dataset (user_id, item_id, rating)\n",
    " \n",
    "\n",
    "# ✅ 1. Create User-Item Matrix\n",
    "#user_item_matrix = df_train.pivot(index=\"user_id\", columns=\"item_id\", values=\"rating\").fillna(0)\n",
    "\n",
    "# ✅ 2. Apply SVD (Truncated SVD for matrix factorization)\n",
    "n_factors = 1  # Number of latent factors\n",
    "new_var = user_item_matrix.values\n",
    "U, S, Vt = svds(new_var, k=n_factors)\n",
    "\n",
    "# Convert singular values into a diagonal matrix\n",
    "S_diag = np.diag(S)\n",
    "\n",
    "# ✅ 3. Reconstruct the matrix\n",
    "reconstructed_matrix = np.dot(np.dot(U, S_diag), Vt)\n",
    "\n",
    "# ✅ 4. Function to Predict Ratings\n",
    "def predict_rating(user, item):\n",
    "    \"\"\"\n",
    "    Predict rating for a given user and item.\n",
    "    :param user: user index\n",
    "    :param item: item index\n",
    "    :return: predicted rating\n",
    "    \"\"\"\n",
    "    if user < reconstructed_matrix.shape[0] and item < reconstructed_matrix.shape[1]:\n",
    "        return reconstructed_matrix[user, item]\n",
    "    else:\n",
    "        return np.nan  # Return NaN if out of bounds\n",
    "\n",
    "# Example prediction for user 0 and item 10\n",
    "predicted_rating = predict_rating(0, 10)\n",
    "print(f\"Predicted rating for user 0 and item 10: {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>evaluate svd</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4665\n"
     ]
    }
   ],
   "source": [
    "reconstructed_ratings = np.dot(U, Vt)\n",
    "reconstructed_ratings\n",
    "user_item_matrix[user_item_matrix>0]\n",
    "from sklearn.metrics import mean_squared_error\n",
    "rmse = np.sqrt(mean_squared_error(user_item_matrix, reconstructed_ratings))\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>TruncatedSVD</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Factors (Embeddings):\n",
      "(1609, 1)\n",
      "Item Factors (Embeddings):\n",
      "(24349, 1)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    " \n",
    "\n",
    "svd = TruncatedSVD(n_components=1)\n",
    "user_factors = svd.fit_transform(user_item_matrix)  # User embeddings\n",
    "item_factors = svd.components_.T  # Item embeddings (transposed)\n",
    "\n",
    "print(\"User Factors (Embeddings):\")\n",
    "print(user_factors.shape)\n",
    "\n",
    "print(\"Item Factors (Embeddings):\")\n",
    "print(item_factors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1620, 25813)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4148\n"
     ]
    }
   ],
   "source": [
    "reconstructed_ratings = np.dot(user_factors, item_factors.T)\n",
    "actual_ratings = user_item_matrix[user_item_matrix > 0]\n",
    "predicted_ratings = reconstructed_ratings[user_item_matrix > 0]\n",
    "rmse = np.sqrt(mean_squared_error(user_item_matrix, reconstructed_ratings))\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1609, 24349) (1609, 24349)\n"
     ]
    }
   ],
   "source": [
    "print(reconstructed_ratings.shape,actual_ratings.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 24349)"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import fastica\n",
    "K, W, S = fastica(user_item_matrix, n_components=1, random_state=0, whiten='unit-variance')\n",
    "u_factors=S\n",
    "i_factors=K \n",
    "i_factors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.4666\n"
     ]
    }
   ],
   "source": [
    "reconstructed_ratings = np.dot(u_factors, i_factors)\n",
    "actual_ratings = user_item_matrix[user_item_matrix > 0]\n",
    "predicted_ratings = reconstructed_ratings[user_item_matrix > 0]\n",
    "rmse = np.sqrt(mean_squared_error(user_item_matrix, reconstructed_ratings))\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>SGD </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, RMSE: 6.2434\n",
      "Epoch 2/20, RMSE: 4.5060\n",
      "Epoch 3/20, RMSE: 3.4950\n",
      "Epoch 4/20, RMSE: 2.9751\n",
      "Epoch 5/20, RMSE: 2.7072\n",
      "Epoch 6/20, RMSE: 2.5424\n",
      "Epoch 7/20, RMSE: 2.4367\n",
      "Epoch 8/20, RMSE: 2.3884\n",
      "Epoch 9/20, RMSE: 2.3546\n",
      "Epoch 10/20, RMSE: 2.3297\n",
      "Epoch 11/20, RMSE: 2.3157\n",
      "Epoch 12/20, RMSE: 2.3015\n",
      "Epoch 13/20, RMSE: 2.2907\n",
      "Epoch 14/20, RMSE: 2.2823\n",
      "Epoch 15/20, RMSE: 2.2646\n",
      "Epoch 16/20, RMSE: 2.2632\n",
      "Epoch 17/20, RMSE: 2.2592\n",
      "Epoch 18/20, RMSE: 2.2589\n",
      "Epoch 19/20, RMSE: 2.2581\n",
      "Epoch 20/20, RMSE: 2.2500\n",
      "Predicted rating for user 0 and item 10: 0.26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class SGDMatrixFactorization:\n",
    "    def __init__(self, num_users, num_items, n_factors=10, learning_rate=0.01, reg_param=0.02, n_epochs=20):\n",
    "        \"\"\"\n",
    "        Initialize the matrix factorization model using SGD.\n",
    "        \"\"\"\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.reg_param = reg_param\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        # Initialize user and item latent factors randomly\n",
    "        self.user_factors = np.random.normal(scale=0.1, size=(num_users, n_factors))\n",
    "        self.item_factors = np.random.normal(scale=0.1, size=(num_items, n_factors))\n",
    "\n",
    "    def train(self, df_train):\n",
    "        \"\"\"\n",
    "        Train the model using stochastic gradient descent (SGD).\n",
    "        :param df_train: Pandas DataFrame with columns ['user_id', 'item_id', 'rating']\n",
    "        \"\"\"\n",
    "        train_data = list(zip(df_train['user'], df_train['item'], df_train['rating']))  # Convert DF to list\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            np.random.shuffle(train_data)  # Shuffle training data for stochastic updates\n",
    "            \n",
    "            for user, item, rating in train_data:\n",
    "                # Predict rating\n",
    "                pred = np.dot(self.user_factors[user], self.item_factors[item])\n",
    "                error = rating - pred\n",
    "\n",
    "                # Update user and item latent factors\n",
    "                self.user_factors[user] += self.learning_rate * (error * self.item_factors[item] - self.reg_param * self.user_factors[user])\n",
    "                self.item_factors[item] += self.learning_rate * (error * self.user_factors[user] - self.reg_param * self.item_factors[item])\n",
    "\n",
    "            # Compute RMSE after each epoch\n",
    "            rmse = self.compute_rmse(df_train)\n",
    "            print(f\"Epoch {epoch + 1}/{self.n_epochs}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "    def compute_rmse(self, df):\n",
    "        \"\"\"\n",
    "        Compute RMSE on given dataset.\n",
    "        \"\"\"\n",
    "        errors = [(rating - np.dot(self.user_factors[user], self.item_factors[item])) ** 2 \n",
    "                  for user, item, rating in zip(df['user'], df['item'], df['rating'])]\n",
    "        return np.sqrt(np.mean(errors))\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        \"\"\"\n",
    "        Predict a rating for a given user-item pair.\n",
    "        \"\"\"\n",
    "        return np.dot(self.user_factors[user], self.item_factors[item])\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Reconstruct the full user-item rating matrix.\n",
    "        \"\"\"\n",
    "        return np.dot(self.user_factors, self.item_factors.T)\n",
    "\n",
    "\n",
    "# Example Usage with DataFrame\n",
    "np.random.seed(42)\n",
    "\n",
    "# Simulated user-item-rating data\n",
    "num_users = 100  # Total number of users\n",
    "num_items = 500 \n",
    "model = SGDMatrixFactorization(user_item_matrix.shape[0], user_item_matrix.shape[1], n_factors=1, learning_rate=0.01, reg_param=0.02, n_epochs=20)\n",
    "model.train(df)\n",
    "\n",
    "# Make a prediction for user 0 and item 10\n",
    "predicted_rating = model.predict(user=0, item=10)\n",
    "print(f\"Predicted rating for user 0 and item 10: {predicted_rating:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>evaluate</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 5.2349\n"
     ]
    }
   ],
   "source": [
    "model.item_factors[:,0]\n",
    "model.user_factors[:,0]\n",
    "\n",
    "\n",
    "reconstructed_ratings = np.dot(model.user_factors, model.item_factors.T)\n",
    "actual_ratings = user_item_matrix[user_item_matrix > 0]\n",
    "predicted_ratings = reconstructed_ratings[user_item_matrix > 0]\n",
    "rmse = np.sqrt(mean_squared_error(user_item_matrix, reconstructed_ratings))\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>ALS</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, RMSE: 6.4685\n",
      "Epoch 2/20, RMSE: 5.1286\n",
      "Epoch 3/20, RMSE: 4.6116\n",
      "Epoch 4/20, RMSE: 4.5472\n",
      "Epoch 5/20, RMSE: 4.6013\n",
      "Epoch 6/20, RMSE: 4.7176\n",
      "Epoch 7/20, RMSE: 4.7445\n",
      "Epoch 8/20, RMSE: 4.7661\n",
      "Epoch 9/20, RMSE: 4.7878\n",
      "Epoch 10/20, RMSE: 4.8086\n",
      "Epoch 11/20, RMSE: 4.8295\n",
      "Epoch 12/20, RMSE: 4.8500\n",
      "Epoch 13/20, RMSE: 4.8702\n",
      "Epoch 14/20, RMSE: 4.8897\n",
      "Epoch 15/20, RMSE: 4.9076\n",
      "Epoch 16/20, RMSE: 4.9234\n",
      "Epoch 17/20, RMSE: 4.9372\n",
      "Epoch 18/20, RMSE: 4.9492\n",
      "Epoch 19/20, RMSE: 4.9594\n",
      "Epoch 20/20, RMSE: 4.9680\n",
      "Predicted rating for user 0 and item 10: 0.89\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "class ALS:\n",
    "    def __init__(self, num_users, num_items, n_factors=10, reg_param=0.02, n_epochs=20):\n",
    "        \"\"\"\n",
    "        Alternating Least Squares (ALS) Matrix Factorization for Collaborative Filtering\n",
    "        :param num_users: Number of unique users\n",
    "        :param num_items: Number of unique items\n",
    "        :param n_factors: Number of latent factors\n",
    "        :param reg_param: Regularization parameter to avoid overfitting\n",
    "        :param n_epochs: Number of epochs to run ALS\n",
    "        \"\"\"\n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.n_factors = n_factors\n",
    "        self.reg_param = reg_param\n",
    "        self.n_epochs = n_epochs\n",
    "\n",
    "        # Initialize the user and item matrices with small random values\n",
    "        self.user_factors = np.random.normal(scale=0.1, size=(num_users, n_factors))\n",
    "        self.item_factors = np.random.normal(scale=0.1, size=(num_items, n_factors))\n",
    "\n",
    "    def train(self, df):\n",
    "        \"\"\"\n",
    "        Train the ALS model on a DataFrame containing user-item-rating interactions.\n",
    "        :param df: Pandas DataFrame containing columns ['user_id', 'item_id', 'rating']\n",
    "        \"\"\"\n",
    "        # Convert DataFrame to a list of tuples (user_id, item_id, rating)\n",
    "        train_data = list(zip(df['user_id'], df['item_id'], df['rating']))\n",
    "\n",
    "        for epoch in range(self.n_epochs):\n",
    "            # Alternating updates\n",
    "            for user, item, rating in train_data:\n",
    "                # Update user matrix\n",
    "                self.user_factors[user] = self.update_user_factors(user, item, rating)\n",
    "                # Update item matrix\n",
    "                self.item_factors[item] = self.update_item_factors(user, item, rating)\n",
    "\n",
    "            # Optionally compute RMSE or other evaluation metrics\n",
    "            rmse = self.compute_rmse(df)\n",
    "            print(f\"Epoch {epoch+1}/{self.n_epochs}, RMSE: {rmse:.4f}\")\n",
    "\n",
    "    def update_user_factors(self, user, item, rating):\n",
    "        \"\"\"\n",
    "        Update user latent factors for a specific user-item-rating triplet\n",
    "        :param user: user index\n",
    "        :param item: item index\n",
    "        :param rating: actual rating\n",
    "        \"\"\"\n",
    "        item_factors = self.item_factors[item]\n",
    "        predicted_rating = np.dot(self.user_factors[user], item_factors)\n",
    "        error = rating - predicted_rating\n",
    "\n",
    "        # Regularized update rule\n",
    "        self.user_factors[user] += self.reg_param * error * item_factors\n",
    "        return self.user_factors[user]\n",
    "\n",
    "    def update_item_factors(self, user, item, rating):\n",
    "        \"\"\"\n",
    "        Update item latent factors for a specific user-item-rating triplet\n",
    "        :param user: user index\n",
    "        :param item: item index\n",
    "        :param rating: actual rating\n",
    "        \"\"\"\n",
    "        user_factors = self.user_factors[user]\n",
    "        predicted_rating = np.dot(user_factors, self.item_factors[item])\n",
    "        error = rating - predicted_rating\n",
    "\n",
    "        # Regularized update rule\n",
    "        self.item_factors[item] += self.reg_param * error * user_factors\n",
    "        return self.item_factors[item]\n",
    "\n",
    "    def compute_rmse(self, df):\n",
    "        \"\"\"\n",
    "        Compute RMSE on the given dataset.\n",
    "        :param df: DataFrame containing ['user_id', 'item_id', 'rating']\n",
    "        \"\"\"\n",
    "        errors = [(rating - np.dot(self.user_factors[user], self.item_factors[item])) ** 2 \n",
    "                  for user, item, rating in zip(df['user_id'], df['item_id'], df['rating'])]\n",
    "        return np.sqrt(np.mean(errors))\n",
    "\n",
    "    def predict(self, user, item):\n",
    "        \"\"\"\n",
    "        Predict a rating for a given user-item pair.\n",
    "        :param user: user index\n",
    "        :param item: item index\n",
    "        \"\"\"\n",
    "        return np.dot(self.user_factors[user], self.item_factors[item])\n",
    "\n",
    "    def full_matrix(self):\n",
    "        \"\"\"\n",
    "        Reconstruct the full user-item rating matrix.\n",
    "        \"\"\"\n",
    "        return np.dot(self.user_factors, self.item_factors.T)\n",
    "\n",
    "# Example usage with a DataFrame\n",
    "np.random.seed(42)\n",
    "\n",
    "# Example DataFrame\n",
    "num_users = user_item_matrix.shape[0]  # Total number of users\n",
    "num_items = user_item_matrix.shape[1]  # Total number of items\n",
    "\n",
    "ratings_dict = {\n",
    "    \"user\": numerical_data['origname_encoded'].values,\n",
    "    \"item\": numerical_data['latlon_encoded'].values,\n",
    "    \"rating\": numerical_data['speed_m_s'].values\n",
    "}\n",
    "\n",
    "\n",
    "df_train = pd.DataFrame({\n",
    "    'user_id': ratings_dict['user'],#np.random.randint(0, num_users, 10000),\n",
    "    'item_id': ratings_dict['item'],#np.random.randint(0, num_items, 10000),\n",
    "    'rating': ratings_dict['rating']#np.random.randint(1, 6, 10000)  # Ratings between 1 and 5\n",
    "})\n",
    "\n",
    "# Train the ALS model\n",
    "model_als = ALS(num_users, num_items, n_factors=1, reg_param=0.02, n_epochs=20)\n",
    "model_als.train(df_train)\n",
    "\n",
    "# Make a prediction for user 0 and item 10\n",
    "predicted_rating = model_als.predict(user=0, item=10)\n",
    "print(f\"Predicted rating for user 0 and item 10: {predicted_rating:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 4.9635\n"
     ]
    }
   ],
   "source": [
    "model_als.item_factors[:,0]\n",
    "model_als.user_factors[:,0]\n",
    "\n",
    "\n",
    "reconstructed_ratings = np.dot(model_als.user_factors, model_als.item_factors.T)\n",
    "actual_ratings = user_item_matrix[user_item_matrix > 0]\n",
    "predicted_ratings = reconstructed_ratings[user_item_matrix > 0]\n",
    "rmse = np.sqrt(mean_squared_error(user_item_matrix, reconstructed_ratings))\n",
    "\n",
    "print(f\"RMSE: {rmse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>item</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>24339</th>\n",
       "      <th>24340</th>\n",
       "      <th>24341</th>\n",
       "      <th>24342</th>\n",
       "      <th>24343</th>\n",
       "      <th>24344</th>\n",
       "      <th>24345</th>\n",
       "      <th>24346</th>\n",
       "      <th>24347</th>\n",
       "      <th>24348</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1609 rows × 24349 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "item  0      1      2      3      4      5      6      7      8      9      \\\n",
       "user                                                                         \n",
       "0       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4       0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...     ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1604    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1605    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1606    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1607    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1608    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "item  ...  24339  24340  24341  24342  24343  24344  24345  24346  24347  \\\n",
       "user  ...                                                                  \n",
       "0     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "2     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "3     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "4     ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "...   ...    ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "1604  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1605  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1606  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1607  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "1608  ...    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0    0.0   \n",
       "\n",
       "item  24348  \n",
       "user         \n",
       "0       0.0  \n",
       "1       0.0  \n",
       "2       0.0  \n",
       "3       0.0  \n",
       "4       0.0  \n",
       "...     ...  \n",
       "1604    0.0  \n",
       "1605    0.0  \n",
       "1606    0.0  \n",
       "1607    0.0  \n",
       "1608    0.0  \n",
       "\n",
       "[1609 rows x 24349 columns]"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> make tiiff</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00000000e+00, -7.39973112e-22, -9.39044320e-22, ...,\n",
       "       -9.00433854e-11, -6.15210312e-10, -3.03035535e-10])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(model.item_factors[:0].shape)\n",
    "user_item_matrix.columns\n",
    "Vt[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_code</th>\n",
       "      <th>value</th>\n",
       "      <th>latlon</th>\n",
       "      <th>lat1</th>\n",
       "      <th>lon1</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>N1</th>\n",
       "      <th>E1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>294600.0_5127900.0</td>\n",
       "      <td>294600.0</td>\n",
       "      <td>5127900.0</td>\n",
       "      <td>13.836189</td>\n",
       "      <td>46.260071</td>\n",
       "      <td>294645.017368</td>\n",
       "      <td>5.127931e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-7.399731e-22</td>\n",
       "      <td>294600.0_5128000.0</td>\n",
       "      <td>294600.0</td>\n",
       "      <td>5128000.0</td>\n",
       "      <td>13.836065</td>\n",
       "      <td>46.260275</td>\n",
       "      <td>294636.220582</td>\n",
       "      <td>5.127954e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-9.390443e-22</td>\n",
       "      <td>294700.0_5127900.0</td>\n",
       "      <td>294700.0</td>\n",
       "      <td>5127900.0</td>\n",
       "      <td>13.837516</td>\n",
       "      <td>46.259918</td>\n",
       "      <td>294746.742210</td>\n",
       "      <td>5.127911e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>-1.312568e-21</td>\n",
       "      <td>294700.0_5128000.0</td>\n",
       "      <td>294700.0</td>\n",
       "      <td>5128000.0</td>\n",
       "      <td>13.836320</td>\n",
       "      <td>46.260495</td>\n",
       "      <td>294656.699882</td>\n",
       "      <td>5.127978e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-1.527884e-21</td>\n",
       "      <td>294700.0_5128100.0</td>\n",
       "      <td>294700.0</td>\n",
       "      <td>5128100.0</td>\n",
       "      <td>13.837469</td>\n",
       "      <td>46.261663</td>\n",
       "      <td>294749.635139</td>\n",
       "      <td>5.128105e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24344</th>\n",
       "      <td>24344</td>\n",
       "      <td>-3.868546e-10</td>\n",
       "      <td>650100.0_5021200.0</td>\n",
       "      <td>650100.0</td>\n",
       "      <td>5021200.0</td>\n",
       "      <td>18.414749</td>\n",
       "      <td>45.315128</td>\n",
       "      <td>650126.763744</td>\n",
       "      <td>5.021248e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24345</th>\n",
       "      <td>24345</td>\n",
       "      <td>-9.083511e-10</td>\n",
       "      <td>650100.0_5021300.0</td>\n",
       "      <td>650100.0</td>\n",
       "      <td>5021300.0</td>\n",
       "      <td>18.414171</td>\n",
       "      <td>45.315231</td>\n",
       "      <td>650081.173576</td>\n",
       "      <td>5.021258e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24346</th>\n",
       "      <td>24346</td>\n",
       "      <td>-9.004339e-11</td>\n",
       "      <td>650200.0_5021000.0</td>\n",
       "      <td>650200.0</td>\n",
       "      <td>5021000.0</td>\n",
       "      <td>18.415474</td>\n",
       "      <td>45.313332</td>\n",
       "      <td>650188.353112</td>\n",
       "      <td>5.021050e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24347</th>\n",
       "      <td>24347</td>\n",
       "      <td>-6.152103e-10</td>\n",
       "      <td>650200.0_5021100.0</td>\n",
       "      <td>650200.0</td>\n",
       "      <td>5021100.0</td>\n",
       "      <td>18.415174</td>\n",
       "      <td>45.314217</td>\n",
       "      <td>650162.492743</td>\n",
       "      <td>5.021147e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24348</th>\n",
       "      <td>24348</td>\n",
       "      <td>-3.030355e-10</td>\n",
       "      <td>650200.0_5021200.0</td>\n",
       "      <td>650200.0</td>\n",
       "      <td>5021200.0</td>\n",
       "      <td>18.415045</td>\n",
       "      <td>45.314789</td>\n",
       "      <td>650150.867234</td>\n",
       "      <td>5.021211e+06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>24349 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       item_code         value              latlon      lat1       lon1  \\\n",
       "0              0  0.000000e+00  294600.0_5127900.0  294600.0  5127900.0   \n",
       "1              1 -7.399731e-22  294600.0_5128000.0  294600.0  5128000.0   \n",
       "2              2 -9.390443e-22  294700.0_5127900.0  294700.0  5127900.0   \n",
       "3              3 -1.312568e-21  294700.0_5128000.0  294700.0  5128000.0   \n",
       "4              4 -1.527884e-21  294700.0_5128100.0  294700.0  5128100.0   \n",
       "...          ...           ...                 ...       ...        ...   \n",
       "24344      24344 -3.868546e-10  650100.0_5021200.0  650100.0  5021200.0   \n",
       "24345      24345 -9.083511e-10  650100.0_5021300.0  650100.0  5021300.0   \n",
       "24346      24346 -9.004339e-11  650200.0_5021000.0  650200.0  5021000.0   \n",
       "24347      24347 -6.152103e-10  650200.0_5021100.0  650200.0  5021100.0   \n",
       "24348      24348 -3.030355e-10  650200.0_5021200.0  650200.0  5021200.0   \n",
       "\n",
       "             lon        lat             N1            E1  \n",
       "0      13.836189  46.260071  294645.017368  5.127931e+06  \n",
       "1      13.836065  46.260275  294636.220582  5.127954e+06  \n",
       "2      13.837516  46.259918  294746.742210  5.127911e+06  \n",
       "3      13.836320  46.260495  294656.699882  5.127978e+06  \n",
       "4      13.837469  46.261663  294749.635139  5.128105e+06  \n",
       "...          ...        ...            ...           ...  \n",
       "24344  18.414749  45.315128  650126.763744  5.021248e+06  \n",
       "24345  18.414171  45.315231  650081.173576  5.021258e+06  \n",
       "24346  18.415474  45.313332  650188.353112  5.021050e+06  \n",
       "24347  18.415174  45.314217  650162.492743  5.021147e+06  \n",
       "24348  18.415045  45.314789  650150.867234  5.021211e+06  \n",
       "\n",
       "[24349 rows x 9 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vals=model.item_factors[:,0]\n",
    "#output_file = \"grid_mapALS.tif\"\n",
    "\n",
    "vals=Vt[0,:]\n",
    "output_file = \"grid_mapSVD.tif\"\n",
    "# vals=H_nmf[:,0]\n",
    "# output_file = \"grid_mapNMF.tif\"\n",
    "\n",
    "# vals=item_factors[:,0]\n",
    "# output_file = \"grid_mapTrunc_SVD.tif\"\n",
    "\n",
    "# vals=i_factors[:,0]\n",
    "# output_file = \"grid_mapTrunc_fastica.tif\"\n",
    "\n",
    "# vals=model.item_factors[:,0]\n",
    "# output_file = \"grid_mapSGD.tif\"\n",
    "\n",
    "# vals=model_als.item_factors[:,0]\n",
    "# output_file = \"grid_mapALS.tif\"\n",
    "\n",
    "frameForTiff =pd.DataFrame(data={\n",
    "    'item_code':user_item_matrix.columns,\n",
    " #   'value':item_factors[:,0]*1000,\n",
    "# 'value':H.T[:,0]*1000,\n",
    "'value':vals,\n",
    "    'latlon':[latlon_dict.get(x) for x in user_item_matrix.columns ]\n",
    "})\n",
    "frameForTiff[['lat1', 'lon1']] = frameForTiff['latlon'].str.split('_', expand=True).astype(float)\n",
    "\n",
    "\n",
    "frameForTiff[\"lon\"] = [lon_dict.get(x) for x in user_item_matrix.columns ]\n",
    "frameForTiff[\"lat\"] = [lat_dict.get(x) for x in user_item_matrix.columns ]\n",
    "frameForTiff[\"N1\"] = [N1_dict.get(x) for x in user_item_matrix.columns ]\n",
    "frameForTiff[\"E1\"] = [E1_dict.get(x) for x in user_item_matrix.columns ]\n",
    "frameForTiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF map saved as 'grid_mapSVD.tif'\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# ✅ 1. Load Data (Example DataFrame)\n",
    "# Replace with actual DataFrame loading\n",
    "df = pd.DataFrame({\n",
    "    'lon': frameForTiff['lat1'] ,  # X-coordinates in EPSG:3765\n",
    "    'lat': frameForTiff['lon1'] ,  # Y-coordinates in EPSG:3765\n",
    "    'value': frameForTiff['value']  # Example values with NaN\n",
    "})\n",
    "\n",
    "# ✅ 2. Define Grid Extent & Resolution\n",
    "resolution = 100  # Set grid cell size in meters (adjust as needed)\n",
    "\n",
    "# Compute grid boundaries\n",
    "min_x, max_x = df['lon'].min(), df['lon'].max()\n",
    "min_y, max_y = df['lat'].min(), df['lat'].max()\n",
    "\n",
    "# Compute grid size\n",
    "cols = int((max_x - min_x) / resolution) + 1\n",
    "rows = int((max_y - min_y) / resolution) + 1\n",
    "\n",
    "# ✅ 3. Create Empty Grid with NaN\n",
    "grid = np.full((rows, cols), np.nan, dtype=np.float32)\n",
    "\n",
    "# ✅ 4. Map DataFrame Values to Grid\n",
    "for _, row in df.iterrows():\n",
    "    col_idx = int((row['lon'] - min_x) / resolution)\n",
    "    row_idx = int((max_y - row['lat']) / resolution)  # Inverted y-axis\n",
    "    grid[row_idx, col_idx] = row['value']\n",
    "\n",
    "# ✅ 5. Define GeoTransform\n",
    "transform = from_origin(min_x, max_y, resolution, resolution)\n",
    "\n",
    "# ✅ 6. Save as GeoTIFF\n",
    "\n",
    "with rasterio.open(\n",
    "    output_file,\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=rows,\n",
    "    width=cols,\n",
    "    count=1,\n",
    "    dtype=np.float32,\n",
    "    crs=\"EPSG:3765\",\n",
    "    transform=transform,\n",
    "    nodata=np.nan\n",
    ") as dst:\n",
    "    dst.write(grid, 1)\n",
    "\n",
    "print(f\"GeoTIFF map saved as '{output_file}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.66425295e-08, 1.09537041e-08, 1.39005235e-08, ...,\n",
       "       1.00161836e-08, 6.84343376e-08, 3.37088565e-08])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H.T[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Sample DataFrame with 'value' column\n",
    "\n",
    "\n",
    "# Split 'latlon' into 'lat' and 'lon'\n",
    " \n",
    "frameForTiff[['lat', 'lon']] = frameForTiff['latlon'].str.split('_', expand=True).astype(float)\n",
    " \n",
    "# Define extent\n",
    "min_lon, max_lon = frameForTiff['lon'].min(), frameForTiff['lon'].max()\n",
    "min_lat, max_lat = frameForTiff['lat'].min(), frameForTiff['lat'].max()\n",
    "\n",
    "# Determine grid resolution (smallest step size)\n",
    "lon_step = np.min(np.diff(np.sort(frameForTiff['lon'].unique())))\n",
    "lat_step = np.min(np.diff(np.sort(frameForTiff['lat'].unique())))\n",
    "\n",
    "# Define grid size\n",
    "cols = int((max_lon - min_lon) / lon_step) + 1\n",
    "rows = int((max_lat - min_lat) / lat_step) + 1\n",
    "\n",
    "# Create an empty raster grid filled with NaN\n",
    "grid = np.full((rows, cols), np.nan, dtype=np.float32)\n",
    "\n",
    "# Fill the grid with 'value' from the DataFrame\n",
    "for _, row in frameForTiff.iterrows():\n",
    "    col_idx = int((row['lon'] - min_lon) / lon_step)\n",
    "    row_idx = int((max_lat - row['lat']) / lat_step)  # Invert Y-axis for raster order\n",
    "    grid[row_idx, col_idx] = row['value']\n",
    "\n",
    "# Define transformation\n",
    "transform = from_origin(min_lon, max_lat, lon_step, lat_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.850781988352537e-05\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[128], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((max_E1 \u001b[38;5;241m-\u001b[39m min_E1) \u001b[38;5;241m/\u001b[39m E1_step) \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Create an empty raster grid filled with NaN\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m grid \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat32\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Fill the grid with 'value' from the DataFrame\u001b[39;00m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m frameForTiff\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[1;32mc:\\Projects\\Faktorizacije\\.venv\\Lib\\site-packages\\numpy\\_core\\numeric.py:361\u001b[0m, in \u001b[0;36mfull\u001b[1;34m(shape, fill_value, dtype, order, device, like)\u001b[0m\n\u001b[0;32m    359\u001b[0m     fill_value \u001b[38;5;241m=\u001b[39m asarray(fill_value)\n\u001b[0;32m    360\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m fill_value\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m--> 361\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mempty\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    362\u001b[0m multiarray\u001b[38;5;241m.\u001b[39mcopyto(a, fill_value, casting\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124munsafe\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m    363\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m a\n",
      "\u001b[1;31mValueError\u001b[0m: array is too big; `arr.size * arr.dtype.itemsize` is larger than the maximum possible size."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio\n",
    "from rasterio.transform import from_origin\n",
    "\n",
    "# Sample DataFrame with 'value' column\n",
    "\n",
    "\n",
    "# Split 'latlon' into 'lat' and 'lon'\n",
    "\n",
    " \n",
    "# Define extent\n",
    "min_N1, max_N1 = frameForTiff['N1'].min(), frameForTiff['N1'].max()\n",
    "min_E1, max_E1 = frameForTiff['E1'].min(), frameForTiff['E1'].max()\n",
    "min_lon, max_lon = frameForTiff['lon'].min(), frameForTiff['lon'].max()\n",
    "min_lat, max_lat = frameForTiff['lat'].min(), frameForTiff['lat'].max()\n",
    "\n",
    "# Determine grid resolution (smallest step size)\n",
    "N1_step = np.min(np.diff(np.sort(frameForTiff['N1'].unique())))\n",
    "E1_step = np.min(np.diff(np.sort(frameForTiff['E1'].unique())))\n",
    "print(N1_step)\n",
    "# Define grid size\n",
    "cols = int((max_N1 - min_N1) / N1_step) + 1\n",
    "rows = int((max_E1 - min_E1) / E1_step) + 1\n",
    "\n",
    "# Create an empty raster grid filled with NaN\n",
    "grid = np.full((rows, cols), np.nan, dtype=np.float32)\n",
    "\n",
    "# Fill the grid with 'value' from the DataFrame\n",
    "for _, row in frameForTiff.iterrows():\n",
    "    col_idx = int((row['N1'] - min_N1) / N1_step)\n",
    "    row_idx = int((max_E1 - row['E1']) / E1_step)  # Invert Y-axis for raster order\n",
    "    grid[row_idx, col_idx] = row['value']\n",
    "\n",
    "# Define transformation\n",
    "transform = from_origin(min_lon, max_lat, N1_step, E1_step)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3557, 4154)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows, cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GeoTIFF map saved as 'grid_map.tif'\n"
     ]
    }
   ],
   "source": [
    "with rasterio.open(\n",
    "    \"grid_map4.tif\",\n",
    "    \"w\",\n",
    "    driver=\"GTiff\",\n",
    "    height=rows,\n",
    "    width=cols,\n",
    "    count=1,\n",
    "    dtype=np.float32,\n",
    "    crs= \"epsg:3765\",  # Change if needed\"epsg:3765\"\n",
    "    transform=transform\n",
    ") as dst:\n",
    "    dst.write(grid, 1)\n",
    "\n",
    "print(\"GeoTIFF map saved as 'grid_map.tif'\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from geopy.distance import geodesic\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python.exe -m pip install --upgrade pip\n",
    "#pip install surprise\n",
    "%pip install --upgrade pip setuptools wheel cython numpy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data=pd.read_csv('numerical_data.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>NMF sklearn</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "ratings_dict = {\n",
    "    \"user\": numerical_data['origname_encoded'].values,\n",
    "    \"item\": numerical_data['latlon_encoded'].values,\n",
    "    \"rating\": numerical_data['speed_m_s'].values\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "print(df)\n",
    "user_item_matrix = df.pivot(index=\"user\", columns=\"item\", values=\"rating\").fillna(0)\n",
    "#print(user_item_matrix)\n",
    "\n",
    "nmf = NMF(n_components=1, init='random', random_state=42)\n",
    "\n",
    "# Factorize user-item matrix into W (Users) and H (Items)\n",
    "W = nmf.fit_transform(user_item_matrix)  # User features\n",
    "H = nmf.components_  # Item features\n",
    "\n",
    "#print(\"User Features Matrix (W):\\n\", W)\n",
    "#print(\"Item Features Matrix (H):\\n\", H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf = NMF(n_components=1, init='random', random_state=42)\n",
    "\n",
    "# Factorize user-item matrix into W (Users) and H (Items)\n",
    "W = nmf.fit_transform(user_item_matrix)  # User features\n",
    "H = nmf.components_  # Item features\n",
    "H.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix['latent']=H.T\n",
    "user_item_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD\n",
    "from surprise import Dataset, Reader, accuracy\n",
    "from surprise.model_selection import cross_validate, train_test_split, GridSearchCV\n",
    "\n",
    "# Scale represents speed possibilities from 0m/s to 9m/s\n",
    "reader = Reader(rating_scale=(0, 5))\n",
    "# The columns must correspond to user id, item id and ratings (in that order).\n",
    "data = Dataset.load_from_df(numerical_data, reader)\n",
    "data.df\n",
    "from surprise import accuracy, Dataset, SVD, NMF, SVDpp,BaselineOnly,KNNBasic,SlopeOne,CoClustering\n",
    "from surprise.model_selection import KFold\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# define a cross-validation iterator\n",
    "#kf = KFold(n_splits=2,shuffle=True)\n",
    "\n",
    "#algo = SVD()\n",
    "algos={\n",
    "    'svd':SVD(),\n",
    "    'NMF':NMF(),\n",
    "    #,'SVDpp':SVDpp(),\n",
    "   # 'BaselineOnly':BaselineOnly(),\n",
    "    #'SlopeOne':SlopeOne(),\n",
    "    'CoClustering':CoClustering()\n",
    "}\n",
    "for  algo in algos:\n",
    "  print(algo)\n",
    "  #print(cross_validate(algos[algo], data, cv=5))\n",
    "  cross_validate(algos[algo], data, measures=[\"RMSE\", \"MAE\"], cv=3, verbose=True)\n",
    "  print()\n",
    "  print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install sklearn\n",
    "#%pip install git+https://github.com/NicolasHug/Surprise.git\n",
    "#%pip install scikit-surprise\n",
    "###%pip install --upgrade pip setuptools wheel\n",
    "\n",
    "!pip install scikit-surprise --no-build-isolation\n",
    "##%pip install cython\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import NMF\n",
    "from sklearn.metrics import mean_squared_error\n",
    "ratings_dict = {\n",
    "    \"user\": numerical_data['origname_encoded'].values,\n",
    "    \"item\": numerical_data['latlon_encoded'].values,\n",
    "    \"rating\": numerical_data['speed_m_s'].values\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(ratings_dict)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_item_matrix = df.pivot(index=\"user\", columns=\"item\", values=\"rating\").fillna(0)\n",
    "#print(user_item_matrix)\n",
    "\n",
    "nmf = NMF(n_components=2, init='random', random_state=42)\n",
    "\n",
    "# Factorize user-item matrix into W (Users) and H (Items)\n",
    "W = nmf.fit_transform(user_item_matrix)  # User features\n",
    "H = nmf.components_  # Item features\n",
    "\n",
    "#print(\"User Features Matrix (W):\\n\", W)\n",
    "#print(\"Item Features Matrix (H):\\n\", H)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Number of clusters\n",
    "num_clusters = 5\n",
    "item_features_df = pd.DataFrame(H.T, columns=[\"Feature 1\", \"Feature 2\"])\n",
    "\n",
    "# Perform clustering on item features\n",
    "#spectral_clustering = SpectralClustering(n_clusters=num_clusters, affinity=\"nearest_neighbors\", random_state=42)\n",
    "#item_clusters = spectral_clustering.fit_predict(H.T)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "item_clusters = kmeans.fit_predict(H.T)\n",
    "# Assign clusters to items\n",
    "item_features_df[\"Cluster\"] = item_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot item clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x=item_features_df[\"Feature 1\"],\n",
    "    y=item_features_df[\"Feature 2\"],\n",
    "    hue=item_features_df[\"Cluster\"],\n",
    "    palette=\"viridis\",\n",
    "    s=100\n",
    ")\n",
    "\n",
    "# Add item labels\n",
    "#\n",
    "plt.xlabel(\"Latent Feature 1\")\n",
    "plt.ylabel(\"Latent Feature 2\")\n",
    "plt.title(\"Item Clusters in Latent Feature Space (NMF)\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Number of clusters\n",
    "num_clusters = 5\n",
    "euser_features_df = pd.DataFrame(W, columns=[\"Feature 1\", \"Feature 2\"])\n",
    "\n",
    "# Perform clustering on item features\n",
    "#spectral_clustering = SpectralClustering(n_clusters=num_clusters, affinity=\"nearest_neighbors\", random_state=42)\n",
    "#item_clusters = spectral_clustering.fit_predict(H.T)\n",
    "kmeans = KMeans(n_clusters=num_clusters, random_state=42, n_init=10)\n",
    "item_clusters = kmeans.fit_predict(W)\n",
    "# Assign clusters to items\n",
    "euser_features_df[\"Cluster\"] = item_clusters\n",
    "euser_features_df[\"Cluster\"] = item_clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot item clusters\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.scatterplot(\n",
    "    x=euser_features_df[\"Feature 1\"],\n",
    "    y=euser_features_df[\"Feature 2\"],\n",
    "    hue=euser_features_df[\"Cluster\"],\n",
    "    palette=\"viridis\",\n",
    "    s=100\n",
    ")\n",
    "\n",
    "# Add item labels\n",
    "#\n",
    "plt.xlabel(\"Latent Feature 1\")\n",
    "plt.ylabel(\"Latent Feature 2\")\n",
    "plt.title(\"Item Clusters in Latent Feature Space (NMF)\")\n",
    "plt.legend(title=\"Cluster\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_matrix = np.dot(W, H)\n",
    "print(\"Predicted Ratings Matrix:\\n\", predicted_matrix)\n",
    "# Convert to DataFrame for easy comparison\n",
    "pred_df = pd.DataFrame(predicted_matrix, index=user_item_matrix.index, columns=user_item_matrix.columns)\n",
    "\n",
    "# Calculate RMSE only for non-zero ratings\n",
    "true_ratings = user_item_matrix.to_numpy().flatten()\n",
    "pred_ratings = pred_df.to_numpy().flatten()\n",
    "mask = true_ratings > 0  # Only compare actual ratings\n",
    "\n",
    "rmse = np.sqrt(mean_squared_error(true_ratings[mask], pred_ratings[mask]))\n",
    "print(f\"RMSE: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install tensorflow numpy pandas scikit-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%conda install -c conda-forge scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
