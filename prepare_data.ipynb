{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prompt: list all zip archive in a folder and create list off strigs of all names\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "def list_zip_archives(folder_path):\n",
    "  \"\"\"Lists all zip archives in a folder and returns their names as a list of strings.\n",
    "\n",
    "  Args:\n",
    "    folder_path: The path to the folder.\n",
    "\n",
    "  Returns:\n",
    "    A list of strings, where each string is the name of a zip archive in the folder.\n",
    "  \"\"\"\n",
    "  zip_files = []\n",
    "  try:\n",
    "    for filename in os.listdir(folder_path):\n",
    "      if filename.endswith(\".zip\") or filename.endswith(\".ZIP\"):\n",
    "        zip_files.append(folder_path+filename)\n",
    "  except FileNotFoundError:\n",
    "    print(f\"Folder not found: {folder_path}\")\n",
    "\n",
    "  return zip_files\n",
    "\n",
    "# Example usage:\n",
    "folder_path = 'GPX_DATA/'  # Replace with your folder path\n",
    "zip_archive_names = list_zip_archives(folder_path)\n",
    "\n",
    "zip_archive_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "tragovi_files=['/content/drive/My Drive/Istraživanja/GSS/ljiljana_tragovi.zip',\n",
    "               '/content/drive/My Drive/Istraživanja/GSS/Potrage.zip',\n",
    "               '/content/drive/My Drive/Istraživanja/GSS/OneDrive_1_5-8-2020.zip']\n",
    "\n",
    "tragovi_files=zip_archive_names\n",
    "\n",
    "broj=0\n",
    "metadata={}\n",
    "for filenameZip in zip_archive_names:\n",
    "  with ZipFile(filenameZip, 'r') as zipObj:\n",
    "    listOfFileNames = zipObj.namelist()\n",
    "    #print(listOfFileNames)\n",
    "    for fileName in listOfFileNames:\n",
    "      metadata.update({broj:fileName})\n",
    "\n",
    "      print(fileName)\n",
    "      broj=broj+1\n",
    "print(broj)\n",
    "print(metadata)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "#tragovi_files=['/content/drive/My Drive/Istraživanja/GSS/ljiljana_tragovi.zip','/content/drive/My Drive/Istraživanja/GSS/Potrage.zip','/content/drive/My Drive/Istraživanja/GSS/OneDrive_1_5-8-2020.zip']\n",
    "tragovi_files=zip_archive_names\n",
    "broj=0\n",
    "metadata={}\n",
    "for filenameZip in tragovi_files:\n",
    "\n",
    "\n",
    "#            # Extract a single file from zip\n",
    "        #zipObj.extract(fileName, '/content/drive/My Drive/Istraživanja/GSS/GPX_FILES_ALL/file_'+str(broj)+'.gpx')\n",
    "\n",
    "        with ZipFile(filenameZip, 'r')  as zf:  # open the zip file\n",
    "            for target_file in zf.namelist():  # loop through the list of files to extract\n",
    "                #if target_file in zf.namelist():  # check if the file exists in the archive\n",
    "                    # generate the desired output name:\n",
    "                    #target_name = os.path.splitext(target_file)[0] + \"_\" + os.path.splitext(file_path)[0] + \".txt\"\n",
    "                    if target_file.endswith('.gpx'):\n",
    "\n",
    "                      target_path ='GPX_DATA_ALL/file_'+str(broj)+'.gpx'#os.path.join(target_dir, target_name)  # output path\n",
    "                      with open(target_path, \"wb\") as f:  # open the output path for writing\n",
    "                        f.write(zf.read(target_file))  # save\n",
    "\n",
    "                      metadata.update({broj:target_file})\n",
    "                      broj=broj+1\n",
    "\n",
    "\n",
    "        print(metadata)\n",
    "        broj=broj+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "a_file = open(\"GPX_DATA_ALL/metadata.csv\", \"w\")\n",
    "a_dict = {\"a\": 1, \"b\": 2}\n",
    "\n",
    "writer = csv.writer(a_file)\n",
    "for key, value in metadata.items():\n",
    "    writer.writerow([key, value])\n",
    "\n",
    "a_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata\n",
    "import pandas as pd\n",
    "meta_d={'filnum':metadata.keys(),'origname':\n",
    "metadata.values()}\n",
    "meta_df=pd.DataFrame( meta_d)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "meta_df.to_csv(\"GPX_DATA_ALL/metadata.csv\",  )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "metadata=pd.read_csv(\"GPX_DATA_ALL/metadata.csv\")\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_all=[]\n",
    "for index, row in metadata.iterrows():\n",
    "    #print(row['filnum'], row['origname'])\n",
    "    #if 'pas' in row['origname']:\n",
    "      #print(row['origname'])\n",
    "    #elif 'psi' in row['origname']:\n",
    "     #3 print(row['origname'])\n",
    "    #if 'svi' in row['origname']:\n",
    "     # print(row['origname'])\n",
    "    if 'spojeno' in row['origname']:\n",
    "      print(row['origname'])\n",
    "    else:\n",
    "\n",
    "      filelist_all.append('GPX_DATA_ALL/file_'+str(row['filnum'])+'.gpx')\n",
    "      #filelist_all.append(      row['origname'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gpxpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gpxpy\n",
    "import gpxpy.gpx\n",
    "#print(len(filelist))\n",
    "def findname(file):\n",
    "    row = metadata.loc[metadata['filnum'] == int(file.split('_')[-1].split('.')[0])]\n",
    "    if not row.empty:\n",
    "        return row.iloc[0]['origname']\n",
    "    return None  # Return None if no match found\n",
    "def read_segments(file):\n",
    "    segments = []\n",
    "    origname = findname(file)\n",
    "\n",
    "    try:\n",
    "        with open(file, 'r', encoding='utf-8', errors='ignore') as gpx_file:\n",
    "            gpx = gpxpy.parse(gpx_file)\n",
    "\n",
    "        d_from_start = 0\n",
    "        for track in gpx.tracks:\n",
    "            for segment in track.segments:\n",
    "                if not segment.points:\n",
    "                    continue  # Skip empty segments\n",
    "\n",
    "                first = segment.points[0]\n",
    "                d_from_start = 0\n",
    "\n",
    "                for i in range(1, len(segment.points)):\n",
    "                    point = segment.points[i]\n",
    "\n",
    "                    segments.append({\n",
    "                        'lat_1': first.latitude, 'lon_1': first.longitude, 'time_1': first.time, 'elev_1': first.elevation,\n",
    "                        'lat_2': point.latitude, 'lon_2': point.longitude, 'time_2': point.time, 'elev_2': point.elevation,\n",
    "                        'origname': origname, 'd_from_start': d_from_start\n",
    "                    })\n",
    "                    d_from_start += 1\n",
    "                    first = point  # Move first point forward\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with {file}: {e}\")\n",
    "\n",
    "    print(\"Done:\", file)\n",
    "    return segments\n",
    "\n",
    "\n",
    "\n",
    "def read_segments_old(file):\n",
    "  segments=[]\n",
    "  #print(mp.current_process())\n",
    "  #print(file)\n",
    "  #file to origname:\n",
    "  origname=findname(file)\n",
    "\n",
    "  try:\n",
    "    gpx_file = open(file, 'r')\n",
    " \n",
    "    gpx = gpxpy.parse(gpx_file)\n",
    "    # print(gpx.length_2d())\n",
    "    d_from_start=0\n",
    "    for track in gpx.tracks:\n",
    "      for segment in track.segments:\n",
    "        first=segment.points[0]\n",
    "        d_from_start=0\n",
    "        #print('duljina:',segment.length_2d())\n",
    "        #segments.append({'lat':first.latitude,'lon':first.longitude})\n",
    "\n",
    "\n",
    "        #for point in segment.points:\n",
    "        i=1\n",
    "        #print(len(segment.points))\n",
    "        while i< len(segment.points):\n",
    "          point=segment.points[i]\n",
    "          i=i+1\n",
    "          #print(point.time)\n",
    "          #print('Point at ({0},{1}) -> {2}'.format(point.latitude, point.longitude, point.elevation) )\n",
    "          #dist=distance_wgs(first.latitude,first.longitude,point.latitude,point.longitude)\n",
    "          #if dist > 0:#0.01:\n",
    "            #print(dist)\n",
    "         #,'dist_wgs':dist\n",
    "\n",
    "          segments.append({'lat_1':first.latitude,'lon_1':first.longitude,'time_1':first.time,'elev_1':first.elevation,\n",
    "                            'lat_2':point.latitude,'lon_2':point.longitude,'time_2':point.time,'elev_2':point.elevation,'origname':origname,'d_from_start':d_from_start})\n",
    "          d_from_start=d_from_start+1\n",
    "          first=point\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  except Exception as e:\n",
    "    print(\"error with \" + file)\n",
    "    print(e)\n",
    "  print('done',file)\n",
    "\n",
    "  return segments\n",
    "\n",
    "findname( 'GPX_DATA_ALL/file_1.gpx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_all=pd.DataFrame()\n",
    "\n",
    "for file in filelist_all:\n",
    "  #gdf_all=pd.concat([gdf_all,gdf],ignore_index=True,verify_integrity=True)\n",
    "  seg_all=pd.concat([seg_all,pd.DataFrame(read_segments(file))],ignore_index=True,verify_integrity=True)\n",
    "seg_all.to_csv('seg_all.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filelist_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Read the file and clean invalid characters\n",
    "with open(\"GPX_DATA_ALL/file_11.gpx\", \"r\", encoding=\"utf-8\", errors=\"ignore\") as file:\n",
    "    gpx_content = file.read()\n",
    "\n",
    "# Remove non-XML characters (optional)\n",
    "gpx_content = re.sub(r\"[^\\x20-\\x7E\\t\\n\\r]\", \"\", gpx_content)  \n",
    "\n",
    "# Parse cleaned GPX content\n",
    "gpx = gpxpy.parse(gpx_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
